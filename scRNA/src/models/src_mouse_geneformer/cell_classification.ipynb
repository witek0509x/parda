{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234afff3",
   "metadata": {},
   "source": [
    "## Geneformer Fine-Tuning for Cell Annotation Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cbe6178-ea4d-478a-80a8-65ffaa4c1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GPU_NUMBER = [0]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(s) for s in GPU_NUMBER])\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9885d9f-00ac-4c84-b6a3-b7b648a90f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 06:28:06.300073: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-18 06:28:07.346404: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import datetime\n",
    "import pickle\n",
    "import subprocess\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from geneformer import DataCollatorForCellClassification\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertForSequenceClassification, Trainer\n",
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd3b98-5409-4105-b7af-f1ff64ea6a72",
   "metadata": {},
   "source": [
    "## Prepare training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5735f1b7-7595-4a02-be17-2c5b970ad81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10X_KC_24_sum' '10X_KO_24_sum']\n",
      "KeyError: \"Column cell_type not in the dataset. Current columns in the dataset: ['input_ids', 'cell_types', 'organ_major', 'disease', 'individual', 'length']\"\n",
      "changing from cell_types to cell_type\n",
      "change finished\n",
      "['endothelial_cell']\n",
      "Dataset({\n",
      "    features: ['input_ids', 'cell_type', 'organ_major', 'disease', 'individual', 'length'],\n",
      "    num_rows: 6831\n",
      "})\n",
      "use_norm: \n",
      "exchange: \n",
      "dataset level: \n"
     ]
    }
   ],
   "source": [
    "# load cell type or disease dataset (includes all tissues)\n",
    "\n",
    "\n",
    "# select fine turning type (ctc: cell type classification or isp: in silico perturbation)\n",
    "f_type = \"isp\"\n",
    "\n",
    "# dataset_name(xxx.dataset path)\n",
    "dataset_name = \"/path/to/your/dataset/to/analysis/xxx.dataset/\"\n",
    "\n",
    "# load dataset\n",
    "train_dataset = load_from_disk(dataset_name)\n",
    "\n",
    "# check and remove column names\n",
    "if f_type == \"isp\":\n",
    "    try:\n",
    "        print(np.unique(train_dataset[\"disease\"]))\n",
    "    except KeyError as e:\n",
    "        print(\"KeyError: {}\".format(e))\n",
    "        print(\"changing to disease\")\n",
    "        train_dataset = train_dataset.rename_column(\n",
    "            \"column name in diseases infomation\", \"disease\"\n",
    "        )\n",
    "        print(\"change finished\")\n",
    "        print(np.unique(train_dataset[\"disease\"]))\n",
    "\n",
    "elif f_type == \"ctc\":\n",
    "    try:\n",
    "        print(np.unique(train_dataset[\"cell_type\"]))\n",
    "    except KeyError as e:\n",
    "        print(\"KeyError: {}\".format(e))\n",
    "        print(\"changing to cell_type\")\n",
    "        train_dataset = train_dataset.rename_column(\n",
    "            \"column name in cell types infomation\", \"cell_type\"\n",
    "        )\n",
    "        print(\"change finished\")\n",
    "        print(np.unique(train_dataset[\"cell_type\"]))\n",
    "\n",
    "else:\n",
    "    print(\"error: select fine turning type (ctc or isp)\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf4ca68-4a0d-4d6e-89a3-609acce6f2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not exist cache files\n"
     ]
    }
   ],
   "source": [
    "# remove cache files in xxx.dataset\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "rmfiles = glob.glob(dataset_name + \"/cache*\")\n",
    "\n",
    "if rmfiles == []:\n",
    "    print(\"not exist cache files\")\n",
    "else:\n",
    "    for tqdm_i2, rmfile in zip(tqdm(rmfiles, desc=\"remove files loop\"), rmfiles):\n",
    "        os.remove(rmfile)\n",
    "    print(\"Finished removeing cache file in it !!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9229668-4239-4de7-8f68-7f3c3e46e089",
   "metadata": {},
   "source": [
    "## Cell Type Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4297a02-4c4c-434c-ae55-3387a0b239b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brain\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d595b8a332f479e8eba64d6c94c864f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/7189 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb2cc68145347ea8df594ff0a72a1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/7189 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d601f33ef9284d0dbe8b2f7b17416180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/7147 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d0b432a938408591328898326b9e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/1429 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell type classification\n",
    "\n",
    "dataset_list = []\n",
    "evalset_list = []\n",
    "organ_list = []\n",
    "target_dict_list = []\n",
    "\n",
    "\n",
    "for organ in Counter(train_dataset[\"organ_major\"]).keys():\n",
    "    # collect list of tissues for fine-tuning (immune and bone marrow are included together)\n",
    "    if organ in [\"bone_marrow\"]:\n",
    "        continue\n",
    "    elif organ == \"immune\":\n",
    "        organ_ids = [\"immune\", \"bone_marrow\"]\n",
    "        organ_list += [\"immune\"]\n",
    "    else:\n",
    "        organ_ids = [organ]\n",
    "        organ_list += [organ]\n",
    "\n",
    "    print(organ)\n",
    "\n",
    "    # filter datasets for given organ\n",
    "    def if_organ(example):\n",
    "        return example[\"organ_major\"] in organ_ids\n",
    "\n",
    "    trainset_organ = train_dataset.filter(if_organ, num_proc=16)\n",
    "\n",
    "    # per scDeepsort published method, drop cell types representing <0.5% of cells\n",
    "    celltype_counter = Counter(trainset_organ[\"cell_type\"])\n",
    "    total_cells = sum(celltype_counter.values())\n",
    "    cells_to_keep = [\n",
    "        k for k, v in celltype_counter.items() if v > (0.005 * total_cells)\n",
    "    ]\n",
    "\n",
    "    def if_not_rare_celltype(example):\n",
    "        return example[\"cell_type\"] in cells_to_keep\n",
    "\n",
    "    trainset_organ_subset = trainset_organ.filter(if_not_rare_celltype, num_proc=16)\n",
    "\n",
    "    # shuffle datasets and rename columns\n",
    "    trainset_organ_shuffled = trainset_organ_subset.shuffle(seed=42)\n",
    "    trainset_organ_shuffled = trainset_organ_shuffled.rename_column(\n",
    "        \"cell_type\", \"label\"\n",
    "    )\n",
    "    trainset_organ_shuffled = trainset_organ_shuffled.remove_columns(\"organ_major\")\n",
    "\n",
    "    # create dictionary of cell types : label ids\n",
    "    target_names = list(Counter(trainset_organ_shuffled[\"label\"]).keys())\n",
    "    target_name_id_dict = dict(zip(target_names, [i for i in range(len(target_names))]))\n",
    "    target_dict_list += [target_name_id_dict]\n",
    "\n",
    "    # change labels to numerical ids\n",
    "    def classes_to_ids(example):\n",
    "        example[\"label\"] = target_name_id_dict[example[\"label\"]]\n",
    "        return example\n",
    "\n",
    "    labeled_trainset = trainset_organ_shuffled.map(classes_to_ids, num_proc=16)\n",
    "\n",
    "    # create 80/20 train/eval splits\n",
    "    labeled_train_split = labeled_trainset.select(\n",
    "        [i for i in range(0, round(len(labeled_trainset) * 0.8))]\n",
    "    )\n",
    "    labeled_eval_split = labeled_trainset.select(\n",
    "        [i for i in range(round(len(labeled_trainset) * 0.8), len(labeled_trainset))]\n",
    "    )\n",
    "\n",
    "    # filter dataset for cell types in corresponding training set\n",
    "    trained_labels = list(Counter(labeled_train_split[\"label\"]).keys())\n",
    "\n",
    "    def if_trained_label(example):\n",
    "        return example[\"label\"] in trained_labels\n",
    "\n",
    "    labeled_eval_split_subset = labeled_eval_split.filter(if_trained_label, num_proc=16)\n",
    "\n",
    "    dataset_list += [labeled_train_split]\n",
    "    evalset_list += [labeled_eval_split_subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e4d33-4d25-4a60-bc2b-63fd2e56fbd5",
   "metadata": {},
   "source": [
    "## Disease Type Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27a87aa2-c8eb-4cf2-8b1e-ec223b416de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brain\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2377c7c5deea487ebe15d10d08e22711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/6831 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60e2262b7cd4e8ab56705cd59a6a6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/6831 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fe05587b3d4e92bb4021f5b7b47297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/6831 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd9102ba18445b98fe4c367ae212d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/1366 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# disease classification\n",
    "\n",
    "dataset_list = []\n",
    "evalset_list = []\n",
    "organ_list = []\n",
    "target_dict_list = []\n",
    "\n",
    "\n",
    "for organ in Counter(train_dataset[\"organ_major\"]).keys():\n",
    "    # collect list of tissues for fine-tuning (immune and bone marrow are included together)\n",
    "\n",
    "    organ_ids = [organ]\n",
    "    organ_list += [organ]\n",
    "\n",
    "    print(organ)\n",
    "\n",
    "    # filter datasets for given organ\n",
    "    def if_organ(example):\n",
    "        return example[\"organ_major\"] in organ_ids\n",
    "\n",
    "    trainset_organ = train_dataset.filter(if_organ, num_proc=16)\n",
    "\n",
    "    # per scDeepsort published method, drop cell types representing <0.5% of cells\n",
    "    celltype_counter = Counter(trainset_organ[\"disease\"])\n",
    "    total_cells = sum(celltype_counter.values())\n",
    "    cells_to_keep = [\n",
    "        k for k, v in celltype_counter.items() if v > (0.005 * total_cells)\n",
    "    ]\n",
    "\n",
    "    def if_not_rare_celltype(example):\n",
    "        return example[\"disease\"] in cells_to_keep\n",
    "\n",
    "    trainset_organ_subset = trainset_organ.filter(if_not_rare_celltype, num_proc=16)\n",
    "\n",
    "    # shuffle datasets and rename columns\n",
    "    trainset_organ_shuffled = trainset_organ_subset.shuffle(seed=42)\n",
    "    trainset_organ_shuffled = trainset_organ_shuffled.rename_column(\"disease\", \"label\")\n",
    "    trainset_organ_shuffled = trainset_organ_shuffled.remove_columns(\"organ_major\")\n",
    "\n",
    "    # create dictionary of cell types : label ids\n",
    "    target_names = list(Counter(trainset_organ_shuffled[\"label\"]).keys())\n",
    "    target_name_id_dict = dict(zip(target_names, [i for i in range(len(target_names))]))\n",
    "    target_dict_list += [target_name_id_dict]\n",
    "\n",
    "    # change labels to numerical ids\n",
    "    def classes_to_ids(example):\n",
    "        example[\"label\"] = target_name_id_dict[example[\"label\"]]\n",
    "        return example\n",
    "\n",
    "    labeled_trainset = trainset_organ_shuffled.map(classes_to_ids, num_proc=16)\n",
    "\n",
    "    # create 80/20 train/eval splits\n",
    "    labeled_train_split = labeled_trainset.select(\n",
    "        [i for i in range(0, round(len(labeled_trainset) * 0.8))]\n",
    "    )\n",
    "    labeled_eval_split = labeled_trainset.select(\n",
    "        [i for i in range(round(len(labeled_trainset) * 0.8), len(labeled_trainset))]\n",
    "    )\n",
    "\n",
    "    # filter dataset for cell types in corresponding training set\n",
    "    trained_labels = list(Counter(labeled_train_split[\"label\"]).keys())\n",
    "\n",
    "    def if_trained_label(example):\n",
    "        return example[\"label\"] in trained_labels\n",
    "\n",
    "    labeled_eval_split_subset = labeled_eval_split.filter(if_trained_label, num_proc=16)\n",
    "\n",
    "    dataset_list += [labeled_train_split]\n",
    "    evalset_list += [labeled_eval_split_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c90d79e9-b6e2-42e0-8cd0-ec7415cbe1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brain': Dataset({\n",
      "    features: ['input_ids', 'cell_type', 'label', 'individual', 'length'],\n",
      "    num_rows: 5465\n",
      "})}\n",
      "{'brain': {'10X_KC_24_sum': 0, '10X_KO_24_sum': 1}}\n",
      "{'brain': Dataset({\n",
      "    features: ['input_ids', 'cell_type', 'label', 'individual', 'length'],\n",
      "    num_rows: 1366\n",
      "})}\n"
     ]
    }
   ],
   "source": [
    "trainset_dict = dict(zip(organ_list, dataset_list))\n",
    "traintargetdict_dict = dict(zip(organ_list, target_dict_list))\n",
    "\n",
    "evalset_dict = dict(zip(organ_list, evalset_list))\n",
    "\n",
    "\n",
    "print(trainset_dict)\n",
    "print(traintargetdict_dict)\n",
    "\n",
    "print(evalset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb110d-ba43-4efc-bc43-1815d6912647",
   "metadata": {},
   "source": [
    "## Fine-Tune With Cell Classification Learning Objective and Quantify Predictive Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd7b1cfb-f5cb-460e-ae77-769522ece054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # calculate accuracy and macro f1 using sklearn's function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return {\"accuracy\": acc, \"macro_f1\": macro_f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaab7a4-cc13-4e8f-b137-ed18ff7b633c",
   "metadata": {},
   "source": [
    "### Please note that, as usual with deep learning models, we **highly** recommend tuning learning hyperparameters for all fine-tuning applications as this can significantly improve model performance. Example hyperparameters are defined below, but please see the \"hyperparam_optimiz_for_disease_classifier\" script for an example of how to tune hyperparameters for downstream applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d24e1ab7-0131-44bd-b458-1ce5ba31853e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# set model parameters\\n# max input size\\nmax_input_size = 2 ** 11  # 2048\\n\\n# set training hyperparameters\\n# max learning rate\\nmax_lr = 9.7e-5\\n# how many pretrained layers to freeze\\nfreeze_layers = 0\\n# number gpus\\nnum_gpus = 1\\n# number cpu cores\\nnum_proc = 16\\n# batch size for training and eval\\ngeneformer_batch_size = 12\\n# learning schedule\\nlr_schedule_fn = \"polynomial\" #choice the \"polynomial\" or \"linear\" or \"cosine\"\\n# warmup steps\\nwarmup_steps = 1_825\\n# number of epochs\\nepochs = 10\\n# optimizer\\noptimizer = \"adamW\"\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set model parameters\n",
    "# max input size\n",
    "max_input_size = 2**11  # 2048\n",
    "\n",
    "# set training hyperparameters\n",
    "# max learning rate\n",
    "max_lr = 5e-5\n",
    "# how many pretrained layers to freeze\n",
    "freeze_layers = 0\n",
    "# number gpus\n",
    "num_gpus = 1\n",
    "# number cpu cores\n",
    "num_proc = 16\n",
    "# batch size for training and eval\n",
    "geneformer_batch_size = 12\n",
    "# learning schedule\n",
    "lr_schedule_fn = \"linear\"  # \"polynomial\", \"linear\", \"cosine\"\n",
    "# warmup steps\n",
    "warmup_steps = 500\n",
    "# number of epochs\n",
    "epochs = 20\n",
    "# optimizer\n",
    "optimizer = \"adamW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05164c24-5fbf-4372-b26c-a43f3777a88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brain\n",
      "{'10X_KC_24_sum': 0, '10X_KO_24_sum': 1}\n",
      "mouse-Geneformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /mnt/keita/data/prog/jupyter/Geneformer/models/240628_155329_mouse-geneformer_20M_DV-n1_PTTMLM_L6_emb256_SL2048_E10_B12_LR0.001_LScosine_WU10000_ACTsilu_Oadamw_DS8/models/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9120' max='9120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9120/9120 27:07, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.680700</td>\n",
       "      <td>0.685030</td>\n",
       "      <td>0.558565</td>\n",
       "      <td>0.551703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.666700</td>\n",
       "      <td>0.655963</td>\n",
       "      <td>0.611274</td>\n",
       "      <td>0.605085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.642200</td>\n",
       "      <td>0.623628</td>\n",
       "      <td>0.659590</td>\n",
       "      <td>0.631523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.501100</td>\n",
       "      <td>0.552069</td>\n",
       "      <td>0.725476</td>\n",
       "      <td>0.722686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.400500</td>\n",
       "      <td>0.523209</td>\n",
       "      <td>0.782577</td>\n",
       "      <td>0.782551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.332500</td>\n",
       "      <td>0.559892</td>\n",
       "      <td>0.811859</td>\n",
       "      <td>0.811350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.557681</td>\n",
       "      <td>0.830161</td>\n",
       "      <td>0.829353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.599117</td>\n",
       "      <td>0.852123</td>\n",
       "      <td>0.851193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.849195</td>\n",
       "      <td>0.848751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.860176</td>\n",
       "      <td>0.859606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.703924</td>\n",
       "      <td>0.870425</td>\n",
       "      <td>0.870053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.705671</td>\n",
       "      <td>0.877745</td>\n",
       "      <td>0.876109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.872621</td>\n",
       "      <td>0.872015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.722194</td>\n",
       "      <td>0.885798</td>\n",
       "      <td>0.884818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.724848</td>\n",
       "      <td>0.882870</td>\n",
       "      <td>0.881896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.785008</td>\n",
       "      <td>0.882870</td>\n",
       "      <td>0.882359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.815912</td>\n",
       "      <td>0.883602</td>\n",
       "      <td>0.883149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.801754</td>\n",
       "      <td>0.884334</td>\n",
       "      <td>0.883735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.800591</td>\n",
       "      <td>0.885066</td>\n",
       "      <td>0.884483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.794345</td>\n",
       "      <td>0.887994</td>\n",
       "      <td>0.887328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/mnt/keita/data/prog/jupyter/Geneformer/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for organ in organ_list:\n",
    "    print(organ)\n",
    "    organ_trainset = trainset_dict[organ]\n",
    "    organ_evalset = evalset_dict[organ]\n",
    "    organ_label_dict = traintargetdict_dict[organ]\n",
    "    print(organ_label_dict)\n",
    "\n",
    "    # set logging steps\n",
    "    logging_steps = round(len(organ_trainset) / geneformer_batch_size / 10)\n",
    "\n",
    "    pretrain_model = \"your mouse-Geneformer name\"\n",
    "\n",
    "    # reload pretrained model\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        \"/path/to/your/mouse-Geneformer/model/{}/models/\".format(pretrain_model),\n",
    "        num_labels=len(organ_label_dict.keys()),\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # define output directory path\n",
    "    current_date = datetime.datetime.now()\n",
    "    datestamp = (\n",
    "        f\"{str(current_date.year)[-2:]}{current_date.month:02d}{current_date.day:02d}\"\n",
    "    )\n",
    "    if f_type == \"isp\":\n",
    "        output_dir = f\"/path/to/your/fine-tuning/model/to/save/in_silico_pretraining/{datestamp}_mouse-geneformer_CellClassifier_{organ}_L{max_input_size}_B{geneformer_batch_size}_LR{max_lr}_LS{lr_schedule_fn}_WU{warmup_steps}_E{epochs}_O{optimizer}_F{freeze_layers}_ISP-{organ}/\"\n",
    "    elif f_type == \"ctc\":\n",
    "        output_dir = f\"/path/to/your/fine-tuning/model/to/save/cell_type_classification/{datestamp}_mouse-geneformer_DiseaseClassifier_{organ}_L{max_input_size}_B{geneformer_batch_size}_LR{max_lr}_LS{lr_schedule_fn}_WU{warmup_steps}_E{epochs}_O{optimizer}_F{freeze_layers}_CTC-{organ}/\"\n",
    "    else:\n",
    "        print(\"error: select fine turining type (ctc or isp)\")\n",
    "        sys.exit(1)\n",
    "    # ensure not overwriting previously saved model\n",
    "    saved_model_test = os.path.join(output_dir, \"pytorch_model.bin\")\n",
    "    if os.path.isfile(saved_model_test) == True:\n",
    "        raise Exception(\"Model already saved to this directory.\")\n",
    "\n",
    "    # make output directory\n",
    "    subprocess.call(f\"mkdir {output_dir}\", shell=True)\n",
    "\n",
    "    # set training arguments\n",
    "    training_args = {\n",
    "        \"learning_rate\": max_lr,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"evaluation_strategy\": \"epoch\",\n",
    "        \"save_strategy\": \"epoch\",\n",
    "        \"logging_steps\": logging_steps,\n",
    "        \"group_by_length\": True,\n",
    "        \"length_column_name\": \"length\",\n",
    "        \"disable_tqdm\": False,\n",
    "        \"lr_scheduler_type\": lr_schedule_fn,\n",
    "        \"warmup_steps\": warmup_steps,\n",
    "        \"weight_decay\": 0.001,\n",
    "        \"per_device_train_batch_size\": geneformer_batch_size,\n",
    "        \"per_device_eval_batch_size\": geneformer_batch_size,\n",
    "        \"num_train_epochs\": epochs,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"output_dir\": output_dir,\n",
    "        # \"max_position_embeddings\": 2**11,\n",
    "    }\n",
    "\n",
    "    training_args_init = TrainingArguments(**training_args)\n",
    "\n",
    "    # create the trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args_init,\n",
    "        data_collator=DataCollatorForCellClassification(),\n",
    "        train_dataset=organ_trainset,\n",
    "        eval_dataset=organ_evalset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    # train the cell type classifier\n",
    "    trainer.train()\n",
    "    predictions = trainer.predict(organ_evalset)\n",
    "    with open(f\"{output_dir}predictions.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(predictions, fp)\n",
    "    trainer.save_metrics(\"eval\", predictions.metrics)\n",
    "    trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f15f51c-7908-4823-aa63-05142dae1b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_660811/676004434.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for tqdm_i2, rmfile in zip(tqdm(rmfiles, desc='remove files loop'), rmfiles) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2221f8fb43b0437c8016ea0a6e977a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "remove files loop:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cacheファイルの削除完了!!\n"
     ]
    }
   ],
   "source": [
    "# remove cache files in xxx.dataset\n",
    "\n",
    "rmfiles = glob.glob(dataset_name + \"/cache*\")\n",
    "# print(rmfiles)\n",
    "for tqdm_i2, rmfile in zip(tqdm(rmfiles, desc=\"remove files loop\"), rmfiles):\n",
    "    os.remove(rmfile)\n",
    "print(\"Finished removing cache files in this dataset!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1bb04-5f59-4071-ac7e-267b96501d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "eba1599a1f7e611c14c87ccff6793920aa63510b01fc0e229d6dd014149b8829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
